Recommendation Engine 
Challenge Presented by Analytics Vidhya 

Trevor Judd, Maria McConkey, Kristen Patterson

Abstract:
Online judge platforms for programming problems need an effective recommendation engine to be able to recommend new engaging and challenging problems to the users. However, it is difficult for online judges to determine how challenging a new problem will be to each user. Recommending problems that are not challenging enough will make a user become unengaged. Recommending problems that are too challenging will make a user want to give up. A good determining factor for recommendations is the number of attempts a programmer at different expertise makes. This recommendation engine uses statistical models which contain information about the problems, the user, and the userâ€™s submissions. The model predicts the number of attempts a user is likely to make when trying to solve problems of similar difficulty. To build these models, R will be used to analyze the data and produce visualizations. The data has been collected and separated into train (70% of the submissions) and test (30%) sets by Analytics Vidhya. It contains 221,850 submissions which comprises 3,571 users and 6,544 problems. To evaluate the model, the F1 score will be used. Based on the F1 scores of similar models that have been built for this issue, an F1 score of 0.4 has been deemed minimally acceptable for a model to address this issue. Producing an accurate model will help online judge platforms be able to engage and challenge their users and users be able to push the boundaries of their skills.
